The seminar *Distributional Models, Semantic Priming and Temporality* will be held in Milan on 08/01/2019 at the 
Department of Computer Science of the University of Milano-Bicocca. 

Location U14, Aula Seminari, Viale Sarca 336 - Milano, Italy.

## Program

14.30 - 14.50: **Does word processing involve visual simulations? An experiment with semantic priming and vision-based distributional models** *Marco Petilli and Alessandra Vergallito*, Department of Psychology, University of Milano-Bicocca.

14.55 - 15.30: **Aspects of Temporality in Word and Entity Embeddings** *Matteo Palmonari and Federico Bianchi*, Department of Computer Science, University of Milano-Bicocca.

15.30 - 16.00: Discussion

## Abstracts of the Talks

### Does word processing involve visual simulations? An experiment with semantic priming and vision-based distributional models. Marco Petilli and Alessandra Vergallito
Findings of sensorimotor activity during conceptual processing suggest a role for visual simulation in language comprehension. Here we adopted a computational approach to test the impact of visual information in a word-processing task. When trained on textual data, distributional models are effective in predicting semantic effects. Here we asked whether these models can predict semantic effects when trained on visual data as well. Speeded naming and lexical decision data for 1184 targets following primes after 200 ms (short SOA) and 1200 ms (long SOA) were extracted from the largest database on semantic priming available (Hutchison, 2013). For each prime-target pair vision estimates of semantic similarity were computed. MatConvNet, a state-of-the-art visual recognition system for computer vision was used to extract distributional properties of prototypic images of prime and target items. Visual similarity between prime and target couples was then quantified as the cosine similarity between their respective distributional representations. In order to assess the impact of vision-based estimates on semantic priming, we evaluated to what extent visual similarity can explain variance in behavioral data over and above language-based estimates. Our results showed that vision-based estimates significantly improved the model fit in the lexical decision task with short SOA. This indicates that distributional models trained on visual experience can predict behavioral performances on a language-based semantic task. Taken together these findings suggest that visual information can affect language processing and, therefore, are coherent with the idea of a visual simulation of the meaning of the words.

# Aspects of Temporality in Word and Entity Embeddings. Matteo Palmonari and Federico Bianchi

+ **Entity Embeddings** Knowledge Graphs (KG) are widely used for knowledge representation. Recently, approaches aimed to represent the KG structure in an embedded space have become increasingly popular for their ability to capture high-level similarities between entities and relations. However, these embedded representations commonly give low consideration to the time aspect. Real-world entities exist and act in a defined temporal interval, consequently time is a valuable element of information in their description. 
In this presentation, we show the influence of time on the embedded representations of entities that are generated from text. The preliminary evaluation shows that generating a specific representation for temporal entities (e.g., years) can result in a more informative entity representation space. We also describe the time-aware similarity metric that can be used to evaluate the similarity between entities by either flattening their time distance or boosting it.

+ **Word Embeddings** Temporal word embeddings have been proposed to support
the analysis of word meaning shifts during time and to study
the evolution of languages. Different approaches have been
proposed to generate vector representations of words that
embed their meaning during a specific time interval. How-
ever, the training process used in these approaches is com-
plex, may be inefficient or it may require large text corpora.
As a consequence, these approaches may be difficult to ap-
ply in resource-scarce domains or by scientists with limited
in-depth knowledge of embedding models. In this paper, we
propose a new heuristic to train temporal word embeddings
based on the Word2vec model. The heuristic consists in us-
ing atemporal vectors as a reference, i.e., as a compass, when
training the representations specific to a given time interval.
The use of the compass simplifies the training process and
makes it more efficient. Experiments conducted using state-
of-the-art datasets and methodologies suggest that our ap-
proach outperforms or equals comparable approaches while
being more robust in terms of the required corpus size.